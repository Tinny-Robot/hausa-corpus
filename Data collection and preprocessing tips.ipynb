{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tips on how to get and preprocess the shared datasets \n",
    "\n",
    "    # Collection and Curation ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "import codecs, json, string, re, time, os, sys, datetime\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOCIAL STREAM CATEGORY I\n",
    "\n",
    "    #Data from Twitter social networks (Twitter) ... using specific usernames and keywords for data collection \n",
    "    \n",
    "    The main collection sources are news channels (from respective websites and corresponding social media handles). This collection mostly consists of well-written text (abidng by formal writing style) to post or break news on social media platforms such as Twitter. The category consist of diverse users that interacts with the post from News Channel. The users' content and their relevant networks are used to collect further data for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE FOLLOWING KEYS NEED TO BE OBTAINED FROM TWITTER TO ACCESS THE API .... \n",
    "access_token = (\"YOUR ACCESS TOKEN HERE\")\n",
    "access_token_secret = (\"YOUR ACCESS TOKEN SECRET HERE\")\n",
    "consumer_key = (\"YOUR CONSUMER KEY HERE\")\n",
    "consumer_secret = (\"YOUR CONSUMER SECRET KEY HERE\")\n",
    "# authentication instance:\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) # required for validation\n",
    "auth.set_access_token(access_token, access_token_secret)#..access after validation of user\n",
    "api =  tweepy.API(auth) # tweepy requires authenticated user to operate\n",
    "#HAUSE-BASED TWITTER ACCOUNTS TO QUERY FOR COLLECTION: \n",
    "#users = ['list of users to retrieve tweets from']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # THE COLLECTION: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all extracts as dataframes: \n",
    "extracts = {'Date':[],'TweetSource':[],'MTAccountID':[],'MainTweet':[],'MainTweetID':[],\\\n",
    "            'MTRTCount':[],'MTweetFVCount':[],'MTFollowerCount':[],'MTFriendsCount':[],\\\n",
    "            'MainACreated':[], 'MTLanguage':[],'RepTAccountID':[],'RepACreated':[],\\\n",
    "            'MTReply':[], 'ReplierName':[],'RepTweetFVCount':[],'RepTRTCount':[],\\\n",
    "            'RepTFollowerCount':[], 'RepTFriendsCount':[],'RepTLanguage':[]}  \n",
    "start = time.time()\n",
    "\n",
    "for user in users:\n",
    "    print(f'processing {user} account')    \n",
    "    \n",
    "    try:\n",
    "        mt_timeline=tweepy.Cursor(api.user_timeline,screen_name=user).items(21)\n",
    "        for main_item in mt_timeline:\n",
    "\n",
    "            main_user = main_item.user # info/metadata about the user\n",
    "            main_tweet = main_item # tweet object with many extractable fields\n",
    "            \n",
    "            # EXTRACT THE REPLIES FROM THE MAIN TWEET VIA SEARCH: \n",
    "            mt_replies=tweepy.Cursor(api.search,q='to:'+user,result_type='recent').items(101)#(203)\n",
    "            for rep_tweet in mt_replies: #for each reply tweet, document the following: \n",
    "                if hasattr(rep_tweet, 'in_reply_to_status_id_str'):\n",
    "                    if (rep_tweet.in_reply_to_status_id_str == main_tweet.id_str):\n",
    "                        #print(f'updating {user} replies ...')\n",
    "                        \n",
    "                        #UPDATE EXTRACTS: MAIN TWEET \n",
    "                        extracts['Date'].append(main_tweet.created_at)\n",
    "                        extracts['TweetSource'].append(user[1:].upper())\n",
    "                        extracts['MTAccountID'].append(main_item.user.id)\n",
    "                        extracts['MainTweet'].append(main_tweet.text)\n",
    "                        extracts['MainTweetID'].append(main_item.id)\n",
    "                        extracts['MTRTCount'].append(main_item.retweet_count)\n",
    "                        extracts['MTFollowerCount'].append(main_item.user.followers_count)\n",
    "                        extracts['MTFriendsCount'].append(main_item.user.friends_count)\n",
    "                        extracts['MTweetFVCount'].append(main_item.user.favourites_count)\n",
    "                        extracts['MainACreated'].append(main_item.user.created_at)\n",
    "                        extracts['MTLanguage'].append(main_item.lang)\n",
    "\n",
    "                        #UPDATE EXTRACTS: REPLYING TWEET:\n",
    "                        extracts['RepTAccountID'].append(rep_tweet.user.id)\n",
    "                        extracts['RepACreated'].append(rep_tweet.user.created_at)\n",
    "                        extracts['MTReply'].append(' '.join(rep_tweet.text.split()[1:]))\n",
    "                        extracts['ReplierName'].append(rep_tweet.user.screen_name)\n",
    "                        extracts['RepTweetFVCount'].append(rep_tweet.user.favourites_count)\n",
    "                        extracts['RepTRTCount'].append(rep_tweet.retweet_count)\n",
    "                        extracts['RepTFollowerCount'].append(rep_tweet.user.followers_count)\n",
    "                        extracts['RepTFriendsCount'].append(rep_tweet.user.friends_count)\n",
    "                        extracts['RepTLanguage'].append(rep_tweet.lang)\n",
    "        \n",
    "        df_temp = pd.DataFrame(extracts)\n",
    "        \n",
    "        #save output: \n",
    "        with open('~/miscellaneous-hausa-corpus1.csv','a') as csv:\n",
    "            df_temp.to_csv(csv, header=False, mode='a',index_label=False)\n",
    "    \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(20*5)\n",
    "        continue\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "stop = time.time()-start\n",
    "print('The process took: ',stop/60, ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TweetSource</th>\n",
       "      <th>MTAccountID</th>\n",
       "      <th>MainTweet</th>\n",
       "      <th>MainTweetID</th>\n",
       "      <th>MTRTCount</th>\n",
       "      <th>MTweetFVCount</th>\n",
       "      <th>MTFollowerCount</th>\n",
       "      <th>MTFriendsCount</th>\n",
       "      <th>MainACreated</th>\n",
       "      <th>MTLanguage</th>\n",
       "      <th>RepTAccountID</th>\n",
       "      <th>RepACreated</th>\n",
       "      <th>MTReply</th>\n",
       "      <th>ReplierName</th>\n",
       "      <th>RepTweetFVCount</th>\n",
       "      <th>RepTRTCount</th>\n",
       "      <th>RepTFollowerCount</th>\n",
       "      <th>RepTFriendsCount</th>\n",
       "      <th>RepTLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-25 01:14:25</td>\n",
       "      <td>BBCHAUSA</td>\n",
       "      <td>18168536</td>\n",
       "      <td>Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...</td>\n",
       "      <td>1342277487536066562</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>806789</td>\n",
       "      <td>49</td>\n",
       "      <td>2008-12-16 18:29:17</td>\n",
       "      <td>in</td>\n",
       "      <td>1147282749981691907</td>\n",
       "      <td>2019-07-05 23:14:57</td>\n",
       "      <td>Abunda ya faru tun last week</td>\n",
       "      <td>nasshameed</td>\n",
       "      <td>3025</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>404</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date TweetSource  MTAccountID  \\\n",
       "0  2020-12-25 01:14:25    BBCHAUSA     18168536   \n",
       "\n",
       "                                           MainTweet          MainTweetID  \\\n",
       "0  Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...  1342277487536066562   \n",
       "\n",
       "   MTRTCount  MTweetFVCount  MTFollowerCount  MTFriendsCount  \\\n",
       "0          4            112           806789              49   \n",
       "\n",
       "          MainACreated MTLanguage        RepTAccountID          RepACreated  \\\n",
       "0  2008-12-16 18:29:17         in  1147282749981691907  2019-07-05 23:14:57   \n",
       "\n",
       "                        MTReply ReplierName  RepTweetFVCount  RepTRTCount  \\\n",
       "0  Abunda ya faru tun last week  nasshameed             3025            0   \n",
       "\n",
       "   RepTFollowerCount  RepTFriendsCount RepTLanguage  \n",
       "0                105               404           in  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(extracts)\n",
    "df.to_csv('~/miscellaneous-hausa-corpus1.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Data Sharing ...  \n",
    "For sentence generation, each main tweet (tweet tweet that atracts/generates replies from other user), is  followed by the corresponding reply as paragraph (n sentences per line). The final data is saved as a text file (*.txt). Each main tweet begins with the prefix MT and the corresponding reply begins with MTR (i.e. main tweet reply). \n",
    "\n",
    "The only preprocessing performed on the data is to remove urls and user mentions  Because some of the replies contain only user mention or emojis, the cleaned version of the data often contain/returne empty space for the MTR, thus, both the raw and cleaned version of the datasets are returned (using the suffix raw and cleaned, respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MainTweetID</th>\n",
       "      <th>MainTweet</th>\n",
       "      <th>MTReply</th>\n",
       "      <th>Date</th>\n",
       "      <th>TweetSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1342444287359909888</td>\n",
       "      <td>Christmas 2020: Tsaron ƴan Najeriya zai zama w...</td>\n",
       "      <td>https://t.co/xNZBHzuoCd</td>\n",
       "      <td>2020-12-25 12:17:14</td>\n",
       "      <td>BBCHAUSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1342441579022266369</td>\n",
       "      <td>Korona ta yi ajalin jagoran ƴan adawan Mali, S...</td>\n",
       "      <td>Too Allah ya kyauta</td>\n",
       "      <td>2020-12-25 12:06:28</td>\n",
       "      <td>BBCHAUSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1342441579022266369</td>\n",
       "      <td>Korona ta yi ajalin jagoran ƴan adawan Mali, S...</td>\n",
       "      <td>Allah yajikansa yasa aljannace makomarsa ameen...</td>\n",
       "      <td>2020-12-25 12:06:28</td>\n",
       "      <td>BBCHAUSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1342441579022266369</td>\n",
       "      <td>Korona ta yi ajalin jagoran ƴan adawan Mali, S...</td>\n",
       "      <td>Ayya Allah ya gafarta masa.</td>\n",
       "      <td>2020-12-25 12:06:28</td>\n",
       "      <td>BBCHAUSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MainTweetID                                          MainTweet  \\\n",
       "8   1342444287359909888  Christmas 2020: Tsaron ƴan Najeriya zai zama w...   \n",
       "9   1342441579022266369  Korona ta yi ajalin jagoran ƴan adawan Mali, S...   \n",
       "10  1342441579022266369  Korona ta yi ajalin jagoran ƴan adawan Mali, S...   \n",
       "11  1342441579022266369  Korona ta yi ajalin jagoran ƴan adawan Mali, S...   \n",
       "\n",
       "                                              MTReply                 Date  \\\n",
       "8                             https://t.co/xNZBHzuoCd  2020-12-25 12:17:14   \n",
       "9                                 Too Allah ya kyauta  2020-12-25 12:06:28   \n",
       "10  Allah yajikansa yasa aljannace makomarsa ameen...  2020-12-25 12:06:28   \n",
       "11                        Ayya Allah ya gafarta masa.  2020-12-25 12:06:28   \n",
       "\n",
       "   TweetSource  \n",
       "8     BBCHAUSA  \n",
       "9     BBCHAUSA  \n",
       "10    BBCHAUSA  \n",
       "11    BBCHAUSA  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/social-media/twitter/corpus1/tweets_corpus1-for-sharing.csv')\n",
    "df = df[['MainTweetID', 'MainTweet', 'MTReply','Date', 'TweetSource']]\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARALLEL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedMainT</th>\n",
       "      <th>CleanedReplyT</th>\n",
       "      <th>Hausa2EngMainT</th>\n",
       "      <th>Hausa2EngReplyT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...</td>\n",
       "      <td>Abunda ya faru tun last week</td>\n",
       "      <td>Jurgen Klopp has won the Fifa World Coach of t...</td>\n",
       "      <td>It's been a while since last week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...</td>\n",
       "      <td>Ku sai yanzu ku ke sawa news</td>\n",
       "      <td>Jurgen Klopp has won the Fifa World Coach of t...</td>\n",
       "      <td>You are now wearing news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ƴan bindiga sun kashe mutum da ƙona buhunan ma...</td>\n",
       "      <td>Allah ya isa tsakaninmu da duk wanda yake da s...</td>\n",
       "      <td>Gunmen kill man and burn sacks of maize in Kaduna</td>\n",
       "      <td>May Allah reach between us and all those who a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ƴan bindiga sun kashe mutum da ƙona buhunan ma...</td>\n",
       "      <td>Innalillahi wa innailaihi rajiun. Wannan kasar...</td>\n",
       "      <td>Gunmen kill man and burn sacks of maize in Kaduna</td>\n",
       "      <td>Innalillahi wa innailaihi rajiun. This country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ƴan bindiga sun kashe mutum da ƙona buhunan ma...</td>\n",
       "      <td>Subhnallah</td>\n",
       "      <td>Gunmen kill man and burn sacks of maize in Kaduna</td>\n",
       "      <td>Subhnallah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CleanedMainT  \\\n",
       "0  Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...   \n",
       "1  Jurgen Klopp ya lashe kyautar Fifa ta gwarzon ...   \n",
       "3  Ƴan bindiga sun kashe mutum da ƙona buhunan ma...   \n",
       "4  Ƴan bindiga sun kashe mutum da ƙona buhunan ma...   \n",
       "5  Ƴan bindiga sun kashe mutum da ƙona buhunan ma...   \n",
       "\n",
       "                                       CleanedReplyT  \\\n",
       "0                       Abunda ya faru tun last week   \n",
       "1                       Ku sai yanzu ku ke sawa news   \n",
       "3  Allah ya isa tsakaninmu da duk wanda yake da s...   \n",
       "4  Innalillahi wa innailaihi rajiun. Wannan kasar...   \n",
       "5                                         Subhnallah   \n",
       "\n",
       "                                      Hausa2EngMainT  \\\n",
       "0  Jurgen Klopp has won the Fifa World Coach of t...   \n",
       "1  Jurgen Klopp has won the Fifa World Coach of t...   \n",
       "3  Gunmen kill man and burn sacks of maize in Kaduna   \n",
       "4  Gunmen kill man and burn sacks of maize in Kaduna   \n",
       "5  Gunmen kill man and burn sacks of maize in Kaduna   \n",
       "\n",
       "                                     Hausa2EngReplyT  \n",
       "0                  It's been a while since last week  \n",
       "1                           You are now wearing news  \n",
       "3  May Allah reach between us and all those who a...  \n",
       "4  Innalillahi wa innailaihi rajiun. This country...  \n",
       "5                                         Subhnallah  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps=pd.read_csv('data/social-media/twitter/parallel-data/parallel-hausa-tweets.csv')\n",
    "ps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEB DATA Category:**\n",
    "\n",
    "    #Web Scrapping using BeutifulSoup package to scrap useful data from relevan websites that provide information in Hausa language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web data ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ƴan sandan sun ce an kai samamen ne a unguwann...</td>\n",
       "      <td>News2021-01-05</td>\n",
       "      <td>WWW.BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mai magana da yawun ƴan sanda Olumuyiwa Adejob...</td>\n",
       "      <td>News2021-01-05</td>\n",
       "      <td>WWW.BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hukumomi sun ce za su tsaurara kai samamen don...</td>\n",
       "      <td>News2021-01-05</td>\n",
       "      <td>WWW.BBC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            NewsText            Theme   Source\n",
       "1  Ƴan sandan sun ce an kai samamen ne a unguwann...  News2021-01-05   WWW.BBC\n",
       "2  Mai magana da yawun ƴan sanda Olumuyiwa Adejob...  News2021-01-05   WWW.BBC\n",
       "3  Hukumomi sun ce za su tsaurara kai samamen don...  News2021-01-05   WWW.BBC"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('/home/ijdutse/analysis/hausa-corpus/data/web-sites/misc-collections-2021-01-05 20:35:14.csv')\n",
    "dfs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PDF WEB FILES ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Bray, ya yi gayyar sanya hannun sayar da ...</td>\n",
       "      <td>KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babban Jami’in Jakadancin, Bray ne ya shaida s...</td>\n",
       "      <td>KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A jawabinsa na marhabin, babban jami’in jakada...</td>\n",
       "      <td>KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Gwamnatin {asar Amirka, ta dage, wajen fa]a]a...</td>\n",
       "      <td>KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Report  \\\n",
       "1  John Bray, ya yi gayyar sanya hannun sayar da ...   \n",
       "2  Babban Jami’in Jakadancin, Bray ne ya shaida s...   \n",
       "3  A jawabinsa na marhabin, babban jami’in jakada...   \n",
       "4  “Gwamnatin {asar Amirka, ta dage, wajen fa]a]a...   \n",
       "\n",
       "                                              Source  \n",
       "1  KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...  \n",
       "2  KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...  \n",
       "3  KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...  \n",
       "4  KasarAmirkaTaYiGayyarSanyaHannunKamfaninAirPea...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dweb =pd.read_csv('/home/ijdutse/analysis/hausa-corpus/data/4share/pdf-web-files.csv')\n",
    "dweb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
